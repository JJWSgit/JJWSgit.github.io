---
title:  "[멋사 AI 7기] 절약"
categories: likelion
tag: [TIL]
toc: true
author_profile: false
sidebar:
    nav: "docs"
search: true
---

:octocat:Saving<br>
<br>

# 오늘의 키워드 : 절약

현업에서 다루는 데이터는 실습에서 다루는 데이터보다 대부분 큰 용량<br>
이 때 컴퓨터 RAM 용량만큼 불러올 수 있음<br>
더 많은 데이터를 불러와서 분석하거나 모델을 만들기 위해서는 메모리를 효율적으로 사용할 수 있어야 함<br>
<br>

:bulb: 절약하는 방법
- 메모리 절약 => downcast<br>
절약을 통해 더 많은 데이터를 불러와서 더 많이 분석할 수 있을지?<br>
- 스토리지(디스크공간) 절약 => parquet<br>
파일 크기를 줄여서 더 많은 파일을 저장할 수 있을까?<br>
<br>

## 메모리 절약 by downcast

데이터의 범위(int64, uint32 등)에 따라 메모리에서 차지하는 용량이 다르다.<br>

![datatype](../../images/2022-10-17-saving/datatype.png)

downcast 는 [pd.to_numeric](https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html) 을 사용한다.<br>
downcast : {'integer', 'signed', 'unsigned', 'float'}, default None<br>
    If not None, and if the data has been successfully cast to a<br>
    numerical dtype (or if the data was numeric to begin with),<br>
    downcast that resulting data to the smallest numerical dtype<br>
    possible according to the following rules:<br>
    <br>
    - 'integer' or 'signed': smallest signed int dtype (min.: np.int8)<br>
    - 'unsigned': smallest unsigned int dtype (min.: np.uint8)<br>
    - 'float': smallest float dtype (min.: np.float32)<br>

- int<br>
음수가 없을 때 unsigned<br>
음수가 있을 때 signed = integer<br>
- float => float - 소수점이나, 결측치 고려
- bool => int8 - 거의 차이 없음
<br>

- object <br>
범주형 형태일 때 => df.astype("category")<br>
게시글 내용처럼 범주의 수가 너무 많다면 적합하지 않다.<br>
<br>

## 스토리지 절약 - 파일 크기 줄이기 by parquet

csv : 행단위 vs parquet : 열단위<br>
열 단위 구분이 압축에 유리하다.<br>
<br>
:pushpin: pyarrow 와 fastparquet 도 설치한다.<br>
engine 에서 쓰이기 때문<br>

[pandas.DataFrame.to_parquet](https://pandas.pydata.org/pandas-docs/version/1.1/reference/api/pandas.DataFrame.to_parquet.html)<br>
<br>
engine : {'auto', 'pyarrow', 'fastparquet'}, default 'auto' Parquet library to use.<br>
    If 'auto', then the option io.parquet.engine is used.<br>
    The default io.parquet.engine behavior is to try 'pyarrow',<br>
    falling back to 'fastparquet' if 'pyarrow' is unavailable.<br>
compression : {'snappy', 'gzip', 'brotli', None}, default 'snappy'<br>
    Name of the compression to use. Use None for no compression.<br>
<br>

![performance](../../images/2022-10-17-saving/parquet_performance.png)

<br>
parquet 파일은 메타 정보를 포함하고 있다.<br>
=> 데이터 수가 적을 때에는 오히려 csv 보다 파일 크기가 클 수 있다.<br>
<br>

### 파일 크기 비교

[os : 기타 운영 체제 인터페이스](https://docs.python.org/ko/3/library/os.html#module-os)

이 모듈은 운영 체제 종속 기능을 사용하는 이식성 있는 방법을 제공합니다.<br>
<br>
os.stat(path, *, dir_fd=None, follow_symlinks=True)<br>
파일 또는 파일 기술자의 상태를 가져옵니다. <br>
주어진 경로에 대해 stat() 시스템 호출과 같은 작업을 수행합니다.<br>
stat_result 객체를 반환합니다.<br>

- st_size<br>
일반 파일 또는 심볼릭 링크면, 바이트 단위의 파일의 크기. <br>
심볼릭 링크의 크기는 포함하고 있는 경로명의 길이이며, 끝나는 널 바이트는 포함하지 않습니다.<br>

os.path : 일반적인 경로명 조작<br>
- os.path.isfile(path)<br>
path가 존재하는 일반 파일이면 True를 반환합니다.<br>
<br>

# 대시보드

## streamlit

[A faster way to build and share data apps](https://streamlit.io/)<br>
<br>

# 오늘의 이모저모
<br>

**PySpark Koalas**<br>
- [Migrating from Koalas to pandas API on Spark — PySpark documentation](https://spark.apache.org/docs/latest/api/python/migration_guide/koalas_to_pyspark.html#)
- [10 minutes to Koalas — Koalas 1.8.2 documentation](https://koalas.readthedocs.io/en/latest/getting_started/10min.html)
- [Migrating from Koalas to pandas API on Spark — PySpark 3.2.1 documentation](https://spark.apache.org/docs/latest/api/python/migration_guide/koalas_to_pyspark.html#)
- [pandas 코드로 대규모 클러스터에서 더 빠르게 빅데이터를 분석 해보자 - Koalas - 박현우 - PyCon Korea 2020 - YouTube](https://www.youtube.com/watch?v=Y9kdUq_qIa8)
<br>

**리눅스 계열 명령어**<br>
ls : 현재 디렉토리 폴더 내부 확인 (윈도우는 dir)<br>
<br>

cd : Change 디렉토리, 현재 디렉토리 위치에 존재하거나 상위 다른 디렉토리로 이동<br>
- ~ : root 디렉토리 이동<br>
- .. : 상위 디렉토리 이동<br>
<br>

mkdir dirName : 현재 디렉토리 위치에서 새로운 디렉토리를 생성<br>
<br>
mv 디렉토리 혹은 파일 이동경로 : 현재 디렉토리 내 디렉토리 또는 파일 이동<br>
mv 디렉토리 혹은 파일 newName : 현재 디렉토리 내 디렉토리 또는 파일 이름 변경<br>
<br>
cp 현재파일명 복사할파일명 : 현재 디렉토리 내 파일 복사<br>
cp -R dir/ : 현재 디렉토리 내 디렉토리 복사<br>
<br>
rm fileName : 현재 디렉토리 내 파일 삭제<br>
rm -rf : 현재 디렉토리 내 디렉토리 삭제<br>
<br>
<br>

<details>
<summary>:bookmark:출처</summary>

- Data type<br>
https://github.com/rougier/numpy-tutorial#quick-references<br>
- pd.to_numeric<br>
https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html<br>
- pandas.DataFrame.to_parquet<br>
https://builtin.com/data-science/numpy-random-seed<br>
- Parquet read performance<br>
https://wesmckinney.com/blog/python-parquet-update/<br>
- os<br>
https://docs.python.org/ko/3/library/os.html#module-os<br>
- streamlit<br>
https://streamlit.io/<br>
- PySpark Koalas<br>
https://spark.apache.org/docs/latest/api/python/migration_guide/koalas_to_pyspark.html#<br>
https://koalas.readthedocs.io/en/latest/getting_started/10min.html<br>
https://spark.apache.org/docs/latest/api/python/migration_guide/koalas_to_pyspark.html#<br>
https://www.youtube.com/watch?v=Y9kdUq_qIa8<br>
</details>
<br>


:mortar_board:**포스팅 공지** <br><br>
작성한 포스팅은 **멋쟁이 사자처럼 AI SCHOOl**의 수업 내용입니다.<br>
{: .notice--success}

