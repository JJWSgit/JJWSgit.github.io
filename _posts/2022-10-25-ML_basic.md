---
title:  "[멋사 AI 7기] 머신러닝 기본"
categories: likelion
tag: [TIL]
toc: true
author_profile: false
sidebar:
    nav: "docs"
search: true
---

:octocat: scikit-learn<br>
<br>

# ML Tools

[scikit-learn](https://scikit-learn.org/stable/index.html)<br>
<br>

the most popular ML framework<br>
사이킷런으로 할 수 있는 6가지 일<br>
1. Classification - Supervised learning
2. Regression - Supervised learning
3. Clustering - Unsupervised learning
4. Dimensionality reduction
5. Model selection
6. Preprocessing - 수치형 변수로 바꿔주는 등<br>
<br>

**장점**<br>
Numpy, Scipy, Matplotlib 기반 제작 => 높은 접근 가능성과 재사용성<br>
간단하고 효율적인 도구<br>
오픈 소스, 상업적 사용가능<br>
<br>

**단점**<br>
딥러닝 및 강화학습은 지원하지 않음<br>
아키텍처를 정의 하기위해 많은 vocabulary를 필요로 하고, 효율적인 컴퓨팅을 위해 GPU가 추가로 필요하기 때문에
사이킷런에서는 지원하지 않음<br>
<br>
:pushpin:sklearn.neural_network에서 간단한 다층 퍼셉트론을 구현<br>
이 모듈에 대한 버그 수정만 허락 중<br>
더 복잡한 딥 러닝 모델을 구현하려면 tensorflow, keras 및 pytorch와 같은 인기 있는 딥 러닝 프레임워크로 전환바람<br>

XGBoost / LightGBM / CatBoost<br>
PyCaret<br>
Prophet<br>

딥러닝<br>
TensorFlow / Keras / PyTorch<br>
Fast.ai - 교육용 목적<br>
Caffe<br>
MXNet<br>
<br>
XAI : 설명가능한 인공지능<br>
<br>

# scikit-learn 과 ML

**기계학습**<br>
지도학습(분류, 회귀) + 비지도학습(군집화, 변환, 연관) + 강화학습 + etc<br>

[choosing the right estimator](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)<br>

||범주형|수치형|
|---|---|---|
|지도학습|분류|회귀|
|비지도학습|군집화|차원축소|

비지도 학습 - feature engineering<br>
<br>

## 머신러닝 과정

fit : 학습 => predict : 예측 => evaluate : 평가<br>

예시) 의사결정나무<br>
1. 모델설정 : model = DecisionTreeClassifier(randoms_state,,,)
2. 학습 : model.fit(X_train, y_train)
3. 예측 : y_predict = model.predict(X_test)
4. 의사결정나무 시각화 <br>
	plot_tree(model, max_depth, feature_names, filled,,,)<br>
5. 피처의 중요도<br>
	model.feature_importances_<br>
6. 정확도 측정<br>
	1) model.score(X_test, y_test)<br>
	2) accuracy_score(y_test, y_predict)<br>
<br>

### 데이터 전처리, Feature

데이터전처리방법<br>
- Normalization : 0에서 1사이의 값으로 만들어줌<br>
수치변수의 범위가 다양할때 normalization을 통해 머신러닝 모델이 데이터를 더 자세히 관찰할 수 있게 함<br>
- Outlier 다른 데이터 예측할 때 영향이 있는 경우가 있다. 사용 여부 고려
- Imputation : 결측치<br>
데이터에 결측치가 있으면 모델링을 할 수 없음<br>
결측치를 채우거나, 제거하거나, 대체하거나 해야 함<br>
- Encoding<br>
문자형태는 머신러닝 알고리즘이 학습 할 수 없음<br>
종류 원핫인코딩 등<br>
<br>
수치형 변수를 범주화하는 이유 몇 가지<br>
머신러닝 알고리즘에 힌트를 줄 수도 있고 과적합을 방지할 수도 있다.<br>

### Modeling

#### 알고리즘

**의사결정나무**<br>
나무를 뒤집어 놓은 모양<br>
스무고개와 유사하게 예/아니오 질문을 이어가며 학습<br>
질문이나 정답을 담을 네모 상자를 노드라 하며 분기가 거듭될 수록 그에 해당되는 데이터가 줄어듬.<br>
<br>
CART(Classification And Regression Tree)<br>
: 분류와 회귀에 모두 사용할 수 있는 Tree<br>
<br>

주요 파라미터<br>
criterion: 가지 분할의 품질을 측정(gini, entropy)<br>
 - 지니불순도<br>
 - 엔트로피<br>
<br>

max_depth: 트리의 최대 깊이<br>
min_samples_split:내부 노드를 분할하는 데 필요한 최소 샘플 수<br>
min_samples_leaf: 리프 노드에 있어야 하는 최소 샘플 수<br>
max_leaf_nodes: 리프 노드 숫자의 제한치<br>
random_state: 추정기의 무작위성을 제어 => 실행했을 때 같은 결과가 나오도록 한다<br>

#### 훈련

overfitting / optimum / underfitting<br>
<br>

# 오늘의 이모저모

선형 대수학 관점에서 행렬(예: 디자인 행렬 X)은 대문자 라틴 문자를 사용하고,<br>
벡터(응답 벡터 y)에는 소문자 라틴 문자를 사용하는 것이 일반적 - [출처](https://stats.stackexchange.com/questions/389395/why-uppercase-for-x-and-lowercase-for-y)<br>
no free lunch<br>
<br>
<br>

<details>
<summary>:bookmark:출처</summary>

- scikit-learn<br>
https://scikit-learn.org/stable/index.html<br>
https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html<br>
- stackexchange<br>
https://stats.stackexchange.com/questions/389395/why-uppercase-for-x-and-lowercase-for-y<br>
</details>
<br>


:mortar_board:**포스팅 공지** <br><br>
작성한 포스팅은 **멋쟁이 사자처럼 AI SCHOOl**의 수업 내용입니다.<br>
{: .notice--success}